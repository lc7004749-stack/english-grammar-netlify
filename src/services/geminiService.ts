// src/services/geminiService.ts
import { SavedProblem } from "../types";

interface SolveOptions {
  image?: {
    base64: string;
    mimeType: string;
  };
  text?: string;
}

type ChatContentPart =
  | { type: "text"; text: string }
  | { type: "image_url"; image_url: { url: string } };

// =============== å·¥å…·å‡½æ•° ===============

const sleep = (ms: number) => new Promise((r) => setTimeout(r, ms));

async function withRetry<T>(fn: () => Promise<T>, maxRetry = 2): Promise<T> {
  let lastErr: any;
  for (let i = 0; i <= maxRetry; i++) {
    try {
      return await fn();
    } catch (e) {
      lastErr = e;
      await sleep(Math.min(2000, 400 * Math.pow(2, i)));
    }
  }
  throw lastErr;
}

function toDataUrl(base64: string, mime: string) {
  const clean = base64.includes(",") ? base64.split(",")[1] : base64;
  return `data:${mime};base64,${clean}`;
}

function buildUserMessage(prompt: string, options: SolveOptions) {
  const parts: ChatContentPart[] = [{ type: "text", text: prompt }];

  if (options.image?.base64 && options.image?.mimeType) {
    parts.push({
      type: "image_url",
      image_url: { url: toDataUrl(options.image.base64, options.image.mimeType) },
    });
  }

  if (options.text?.trim()) {
    parts.push({ type: "text", text: `\n\nã€é¢˜ç›®æ–‡æœ¬ã€‘\n${options.text.trim()}` });
  }

  return [{ role: "user", content: parts }];
}

function pickContent(json: any): string {
  return json?.choices?.[0]?.message?.content ?? "";
}

// å»æ‰æ¨¡å‹å¶å°”è¾“å‡ºçš„ ```html ... ``` åŒ…è£¹
function stripCodeFences(s: string): string {
  return (s || "")
    .replace(/```html\s*/gi, "")
    .replace(/```/g, "")
    .replace(/~~~html\s*/gi, "")
    .replace(/~~~/g, "")
    .trim();
}

// ç®€å•åˆ¤å®šï¼šæ˜¯å¦å« Markdown è¿¹è±¡ï¼ˆç”¨äºå…œåº•äºŒæ¬¡çº åï¼‰
function looksLikeMarkdown(s: string): boolean {
  const t = s || "";
  if (t.includes("```") || t.includes("~~~")) return true;
  if (/\*\*.+\*\*/.test(t)) return true; // **bold**
  if (/^#{1,6}\s/m.test(t)) return true; // # title
  if (/^\s*[-*+]\s+/m.test(t)) return true; // - list
  return false;
}

// =============== LLM è°ƒç”¨ï¼ˆå¯¹æ¥ Netlify Functionsï¼‰ ===============
// è¿™é‡Œå‡è®¾ä½ çš„ /.netlify/functions/llm å·²ç»åšäº† â€œè½¬å‘åˆ° /chat/completionsâ€
// å› ä¸ºä½ ç°åœ¨ç«™ç‚¹èƒ½ç”Ÿæˆå†…å®¹ï¼Œè¯´æ˜è¿™ä¸ªæ¥å£æ˜¯é€šçš„ã€‚
async function callLLMChatCompletions(payload: any): Promise<any> {
  const res = await fetch("/.netlify/functions/llm", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify(payload),
  });

  if (!res.ok) {
    const txt = await res.text().catch(() => "");
    throw new Error(txt || `LLM HTTP ${res.status}`);
  }
  return await res.json();
}

// =============== 1ï¼‰é¢˜å¹²æ ¸å¯¹/çº é”™ï¼ˆçº¯æ–‡æœ¬ï¼‰ ===============

export const verifyProblem = async (options: SolveOptions): Promise<string> => {
  const prompt = `ä½ æ˜¯â€œå°å­¦è‹±è¯­é¢˜å¹²è´¨æ£€è€å¸ˆâ€ã€‚è¯·å®Œæˆé¢˜å¹²æ ¸å¯¹/çº é”™ï¼š
1) å¦‚æœæœ‰ä¹±ç ã€ç¼ºå­—ã€é‡å¤ã€åˆ†é¡µæ–­å¥ï¼Œè¯·è‡ªåŠ¨ä¿®å¤æˆâ€œå¯åšé¢˜çš„å®Œæ•´é¢˜ç›®â€ã€‚
2) åªè¾“å‡ºã€ä¿®å¤åçš„é¢˜ç›®æ­£æ–‡ã€‘ï¼ˆä¸è¦è§£é‡Šã€ä¸è¦æ ‡é¢˜ã€ä¸è¦ç¼–å·ï¼‰ã€‚
3) è‹±è¯­å¤§å°å†™ã€æ ‡ç‚¹ã€æ¢è¡Œå°½é‡ä¿ç•™é¢˜ç›®åŸæ ·ã€‚
`;

  return await withRetry(async () => {
    const payload = {
      model: (import.meta as any).env.VITE_LLM_MODEL || "gpt-4o-mini",
      messages: buildUserMessage(prompt, options),
      temperature: 0.2,
    };
    const json = await callLLMChatCompletions(payload);
    return pickContent(json).trim();
  });
};

// =============== 2ï¼‰è§£æï¼ˆå¿…é¡»è¿”å›ï¼šçº¯ HTML ç‰‡æ®µï¼‰ ===============

export const solveProblem = async (options: SolveOptions): Promise<string> => {
  const basePrompt = `ä½ ç°åœ¨çš„èº«ä»½æ˜¯â€œèµ„æ·±è‹±è¯­ç§æ•™â€ï¼Œé¢å‘å°å­¦é«˜å¹´çº§å­©å­è®²è§£ã€‚

ã€æœ€é‡è¦çš„ç¡¬è§„åˆ™ã€‘
- ä½ åªèƒ½è¾“å‡ºâ€œå¯ç›´æ¥æ¸²æŸ“çš„ HTML ç‰‡æ®µâ€ï¼Œå¿…é¡»ä»¥ <div å¼€å¤´ï¼Œä»¥ </div> ç»“å°¾ã€‚
- ä¸¥ç¦è¾“å‡º Markdownï¼šä¸å…è®¸å‡ºç° **ã€#ã€-ã€>ã€\`\`\`ã€~~~ ç­‰ä»»ä½• Markdown ç¬¦å·ã€‚
- å¦‚éœ€å¼ºè°ƒè¯·ç”¨ <strong>ï¼Œæ ‡é¢˜ç”¨ <h3>ï¼Œåˆ—è¡¨ç”¨ <ul><li>ã€‚
- ä¸è¦è¾“å‡ºè§£é‡Šæ–‡å­—ï¼Œä¸è¦è¾“å‡ºâ€œä¸‹é¢æ˜¯â€¦â€ï¼Œä¸è¦è¾“å‡ºä»£ç å—å›´æ ã€‚
- åªè¾“å‡º HTMLï¼Œä¸è¦è¾“å‡º JSONã€‚

ã€è¾“å‡ºè¦æ±‚ã€‘
- ç›´æ¥ä» <div> å¼€å§‹å†™ï¼Œä¸è¦å†™ <!doctype>ã€<html>ã€<head>ã€‚
- å¿…é¡»ä½¿ç”¨è¿™äº› class åï¼ˆç”¨äºå¥—ç”¨æˆ‘ç°æœ‰é¡µé¢æ ·å¼ï¼‰ï¼š
  tags-container / level-tag grammar
  highlight-legend / legend-item / legend-dot subject|verb|tense|object|keyword
  original-problem
  reading-tips
  grammar-analysis
  final-answer
  subject-highlight / verb-highlight / tense-highlight / object-highlight / keyword-highlight

ã€å¿…é¡»åŒ…å«ç»“æ„ï¼ˆç…§ç€å†™ï¼‰ã€‘

<div class="tags-container">
  <span class="level-tag grammar">è€ƒç‚¹1</span>
  <span class="level-tag grammar">è€ƒç‚¹2</span>
</div>

<div class="highlight-legend">
  <div class="legend-item"><span class="legend-dot subject"></span>ä¸»è¯­</div>
  <div class="legend-item"><span class="legend-dot verb"></span>è°“è¯­/åŠ¨è¯</div>
  <div class="legend-item"><span class="legend-dot tense"></span>æ—¶æ€/æ—¶é—´</div>
  <div class="legend-item"><span class="legend-dot object"></span>å®¾è¯­/åè¯</div>
  <div class="legend-item"><span class="legend-dot keyword"></span>å…³é”®è¯/ä»‹è¯</div>
</div>

<div class="original-problem">
  <!-- æŠŠé¢˜ç›®å¤è¿°å‡ºæ¥ï¼Œå¹¶ç”¨é«˜äº® span åŒ…ä½å…³é”®æˆåˆ† -->
</div>

é«˜äº®è§„åˆ™ï¼š
- ä¸»è¯­ï¼š<span class="subject-highlight">...</span>
- åŠ¨è¯/è°“è¯­ï¼š<span class="verb-highlight">...</span>
- æ—¶æ€/æ—¶é—´/é¢‘ç‡ï¼š<span class="tense-highlight">...</span>
- å®¾è¯­/åè¯ï¼š<span class="object-highlight">...</span>
- ä»‹è¯/åŠ©åŠ¨è¯/å›ºå®šæ­é…ï¼š<span class="keyword-highlight">...</span>

<div class="reading-tips">
  <h3>ğŸ•µï¸ èµ„æ·±ç§æ•™Â·ç ´é¢˜çœ¼</h3>
  <ul class="list-none pl-0 mt-3 space-y-4">
    <li class="flex items-start gap-3">
      <span class="flex-shrink-0 font-bold text-orange-700 bg-orange-50 px-2 py-1 rounded border border-orange-200 text-sm mt-0.5">ğŸ‘€ 1. ç›¯ä½ä¿¡å·</span>
      <div class="text-slate-700 leading-relaxed">...</div>
    </li>
    <li class="flex items-start gap-3">
      <span class="flex-shrink-0 font-bold text-indigo-700 bg-indigo-50 px-2 py-1 rounded border border-indigo-200 text-sm mt-0.5">ğŸ§  2. è§„åˆ™å˜å½¢</span>
      <div class="text-slate-700 leading-relaxed">...</div>
    </li>
  </ul>
</div>

<div class="grammar-analysis">
  <h3>ğŸ“š æ ¸å¿ƒè¯­æ³•Â·è®²ç»™å­©å­å¬</h3>
  <p class="mb-2">ç”¨å­©å­èƒ½æ‡‚çš„æ¯”å–»è®²æ¸…æ¥šè§„åˆ™ã€‚</p>
  <div class="bg-white/60 p-3 rounded-lg border border-purple-100 mt-2">
    <p class="text-sm font-bold text-purple-700">ğŸŒ° ä¸¾ä¸ªæ —å­ï¼š</p>
    <p class="text-slate-600 text-sm">ç»™ä¸€ä¸ªç±»ä¼¼å¥å­ï¼šåŸå¥ â†’ ç–‘é—®å¥/ç­”æ¡ˆã€‚</p>
  </div>
</div>

<div class="final-answer">âœ… æ­£ç¡®ç­”æ¡ˆï¼š...</div>

ã€é¢˜ç›®ã€‘ï¼ˆæœ‰å›¾ç‰‡ä»¥å›¾ç‰‡ä¸ºå‡†ï¼›æœ‰æ–‡å­—ä»¥æ–‡å­—ä¸ºå‡†ï¼‰ï¼š`;

  const firstTry = await withRetry(async () => {
    const payload = {
      model: (import.meta as any).env.VITE_LLM_MODEL || "gpt-4o-mini",
      messages: buildUserMessage(basePrompt, options),
      temperature: 0.25,
    };
    const json = await callLLMChatCompletions(payload);
    return stripCodeFences(pickContent(json));
  });

  // å…œåº•çº åï¼šå¦‚æœä»åƒ Markdownï¼Œåˆ™å¼ºåˆ¶æ”¹å†™ä¸º HTML
  if (!looksLikeMarkdown(firstTry)) return firstTry;

  const repairPrompt = `ä½ åˆšæ‰çš„è¾“å‡ºå«æœ‰ Markdown ç—•è¿¹ï¼ˆä¾‹å¦‚ **ã€#ã€-ã€\`\`\` ç­‰ï¼‰ã€‚
è¯·ä½ æŠŠâ€œåˆšæ‰çš„å†…å®¹â€æ”¹å†™ä¸ºã€çº¯ HTML ç‰‡æ®µã€‘ï¼š
- å¿…é¡»ä»¥ <div å¼€å¤´ï¼Œä»¥ </div> ç»“å°¾
- ä¸¥ç¦å‡ºç°ä»»ä½• Markdown ç¬¦å·
- è¯­ä¹‰ä¿æŒä¸€è‡´
- ç»§ç»­ä½¿ç”¨æˆ‘è¦æ±‚çš„ class ç»“æ„ï¼ˆtags-containerã€highlight-legendã€original-problemã€reading-tipsã€grammar-analysisã€final-answer ç­‰ï¼‰

ã€åˆšæ‰çš„å†…å®¹ã€‘ï¼š
${firstTry}`;

  return await withRetry(async () => {
    const payload = {
      model: (import.meta as any).env.VITE_LLM_MODEL || "gpt-4o-mini",
      messages: [{ role: "user", content: repairPrompt }],
      temperature: 0.1,
    };
    const json = await callLLMChatCompletions(payload);
    return stripCodeFences(pickContent(json));
  });
};

// =============== 3ï¼‰é”™é¢˜æœ¬è¯Šæ–­ï¼ˆHTML ç‰‡æ®µï¼‰ ===============

export const analyzeProblemHistory = async (problems: SavedProblem[]): Promise<string> => {
  const prompt = `ä½ æ˜¯æ•™ç ”å‘˜ã€‚åŸºäºâ€œé¢˜åº“è®°å½•â€è¾“å‡ºä¸€ä»½ã€å­¦ä¹ è¯Šæ–­æŠ¥å‘Šã€‘çš„çº¯ HTML ç‰‡æ®µï¼ˆä¸¥ç¦ Markdownï¼‰ã€‚
è¦æ±‚ï¼šé€‚åˆå®¶é•¿é˜…è¯»ï¼›åŒ…å«ï¼šå¸¸é”™ç‚¹ã€å»ºè®®ç»ƒæ³•ã€ä¸‹æ¬¡å¤ä¹ é‡ç‚¹ã€‚
åªè¾“å‡º HTMLï¼Œä¸è¦è¾“å‡ºè§£é‡Šï¼Œä¸è¦è¾“å‡º Markdownã€‚
é¢˜åº“JSONï¼š\n${JSON.stringify(problems).slice(0, 120000)}`;

  return await withRetry(async () => {
    const payload = {
      model: (import.meta as any).env.VITE_LLM_MODEL || "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.4,
    };
    const json = await callLLMChatCompletions(payload);
    const html = stripCodeFences(pickContent(json));
    return looksLikeMarkdown(html) ? stripCodeFences(html) : html;
  });
};

// =============== 4ï¼‰å˜å¼è®­ç»ƒï¼ˆHTML ç‰‡æ®µï¼šé¢˜ç›® + details ç­”æ¡ˆè§£æï¼‰ ===============

export const generateDrills = async (
  originalProblem: string,
  solutionContextHtml: string
): Promise<string> => {
  const prompt = `ä½ æ˜¯ä¸€ä½å°å­¦è‹±è¯­è¯­æ³•è€å¸ˆã€‚å›´ç»•â€œåŸé¢˜â€ç”Ÿæˆã€6é“åŒå‹å˜å¼è®­ç»ƒã€‘å¹¶ç»™å‡ºç­”æ¡ˆè§£æã€‚
å¿…é¡»è¾“å‡ºã€çº¯ HTML ç‰‡æ®µã€‘ï¼Œä¸¥ç¦ Markdownï¼Œä¸¥ç¦ \`\`\`ã€~~~ã€‚
ç»“æ„è¦æ±‚ï¼š
- å¤–å±‚ä¸è¦å†™ <html><head>ï¼Œåªè¾“å‡ºå†…å®¹ç‰‡æ®µ
- ç”¨ <div class="drill-item"> åŒ…æ¯ä¸€é¢˜
- é¢˜å¹²æ”¾ <div class="drill-question">
- ç­”æ¡ˆè§£ææ”¾ <div class="drill-answer"><details>...</details></div>
- æ¯é¢˜ç»™ 4 ä¸ªé€‰é¡¹ï¼ˆA/B/C/Dï¼‰æˆ–æŒ‰åŸé¢˜é¢˜å‹ç»„ç»‡
- è¯­è¨€é€‚åˆå°å­¦é«˜å¹´çº§ï¼Œè§£æç®€æ´ä½†è®²æ¸…è§„åˆ™
åŸé¢˜ï¼š\n${originalProblem}\n\nå‚è€ƒè§£ç­”ï¼ˆHTMLï¼‰ï¼š\n${solutionContextHtml}`;

  const first = await withRetry(async () => {
    const payload = {
      model: (import.meta as any).env.VITE_LLM_MODEL || "gpt-4o-mini",
      messages: [{ role: "user", content: prompt }],
      temperature: 0.6,
    };
    const json = await callLLMChatCompletions(payload);
    return stripCodeFences(pickContent(json));
  });

  if (!looksLikeMarkdown(first)) return first;

  const fixPrompt = `ä½ çš„è¾“å‡ºå« Markdown ç—•è¿¹ã€‚è¯·å°†å…¶æ”¹å†™æˆã€çº¯ HTML ç‰‡æ®µã€‘å¹¶ä¿æŒç»“æ„ä¸å˜ï¼š
- ä¸¥ç¦å‡ºç° **ã€#ã€-ã€\`\`\`ã€~~~ ç­‰ Markdown ç¬¦å·
- åªè¾“å‡º HTML
ã€å¾…æ”¹å†™å†…å®¹ã€‘ï¼š
${first}`;

  return await withRetry(async () => {
    const payload = {
      model: (import.meta as any).env.VITE_LLM_MODEL || "gpt-4o-mini",
      messages: [{ role: "user", content: fixPrompt }],
      temperature: 0.1,
    };
    const json = await callLLMChatCompletions(payload);
    return stripCodeFences(pickContent(json));
  });
};

// =============== 5ï¼‰è¯­éŸ³ï¼ˆå¯é€‰ï¼šå¦‚æœä½ çš„ä¸­è½¬æ”¯æŒ TTSï¼‰ ===============

export const generateSpeech = async (solutionHtml: string): Promise<string> => {
  // æŠŠ HTML å˜æˆç®€çŸ­å¯è¯»æ–‡æœ¬
  const text = (solutionHtml || "")
    .replace(/<[^>]*>/g, " ")
    .replace(/\s+/g, " ")
    .trim()
    .slice(0, 1200);

  return await withRetry(async () => {
    const res = await fetch("/.netlify/functions/tts", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ text: `æˆ‘æ¥è®²è§£ï¼š${text}` }),
    });
    if (!res.ok) {
      const txt = await res.text().catch(() => "");
      throw new Error(txt || `TTS HTTP ${res.status}`);
    }
    const json = await res.json();
    return json?.audio_base64 || "";
  });
};
// ================== å…¼å®¹ App.tsx çš„è¡¥é½å¯¼å‡º ==================

// base64 è§£ç ï¼ˆç»™ TTS / éŸ³é¢‘ç”¨ï¼‰
export function decodeBase64(base64: string): Uint8Array {
  const binary = atob(base64);
  const len = binary.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binary.charCodeAt(i);
  }
  return bytes;
}

// PCM â†’ AudioBufferï¼ˆå¦‚æœ UI é‡Œç”¨åˆ°äº†ï¼‰
export function decodePcmAudio(
  pcmData: Uint8Array,
  sampleRate = 24000
): AudioBuffer {
  const audioCtx = new (window.AudioContext || (window as any).webkitAudioContext)();
  const buffer = audioCtx.createBuffer(1, pcmData.length, sampleRate);
  const channelData = buffer.getChannelData(0);

  for (let i = 0; i < pcmData.length; i++) {
    channelData[i] = (pcmData[i] - 128) / 128;
  }
  return buffer;
}
